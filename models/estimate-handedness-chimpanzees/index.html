<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel="shortcut icon" type="image/png" href="/TuringModels.jl/assets/favicon.png"/> <link rel=stylesheet  href="/TuringModels.jl/libs/highlight/github.min.css"> <link rel=stylesheet  href="/TuringModels.jl/css/franklin.css"> <title>Estimate handedness for each Chimpanzee</title> <div class=franklin-content > <div class=top-bar > <a href="/TuringModels.jl/">TuringModels</a> </div> <h1>Estimate handedness for each Chimpanzee</h1> </div> <div class=franklin-content > <p>This is model <code>m10.4</code> in Statistical Rethinking Edition 1.</p> <div class=franklin-toc ><ol><li><a href="#data">Data</a><li><a href="#model">Model</a><li><a href="#output">Output</a><li><a href="#original_output">Original output</a></ol></div> <h2 id=data ><a href="#data">Data</a></h2> <pre><code class="julia hljs"><span class=hljs-keyword >import</span> CSV
<span class=hljs-keyword >import</span> TuringModels

<span class=hljs-keyword >using</span> DataFrames
<span class=hljs-keyword >using</span> StatsFuns

data_path = joinpath(TuringModels.project_root, <span class=hljs-string >&quot;data&quot;</span>, <span class=hljs-string >&quot;chimpanzees.csv&quot;</span>)
df = CSV.read(data_path, DataFrame; delim=<span class=hljs-string >&#x27;;&#x27;</span>)
first(df, <span class=hljs-number >10</span>)</code></pre><pre><code class="plaintext hljs">10×8 DataFrame
 Row │ actor  recipient  condition  block  trial  prosoc_left  chose_prosoc  pulled_left
     │ Int64  String     Int64      Int64  Int64  Int64        Int64         Int64
─────┼───────────────────────────────────────────────────────────────────────────────────
   1 │     1  NA                 0      1      2            0             1            0
   2 │     1  NA                 0      1      4            0             0            1
   3 │     1  NA                 0      1      6            1             0            0
   4 │     1  NA                 0      1      8            0             1            0
   5 │     1  NA                 0      1     10            1             1            1
   6 │     1  NA                 0      1     12            1             1            1
   7 │     1  NA                 0      2     14            1             0            0
   8 │     1  NA                 0      2     16            1             0            0
   9 │     1  NA                 0      2     18            0             1            0
  10 │     1  NA                 0      2     20            0             1            0</code></pre> <h2 id=model ><a href="#model">Model</a></h2> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> Turing

<span class=hljs-meta >@model</span> m10_4(y, actors, x₁, x₂) = <span class=hljs-keyword >begin</span>
    <span class=hljs-comment ># Number of unique actors in the data set</span>
    N_actor = length(unique(actors))

    <span class=hljs-comment ># Set an TArray for the priors/param</span>
    α ~ filldist(Normal(<span class=hljs-number >0</span>, <span class=hljs-number >10</span>), N_actor)
    βp ~ Normal(<span class=hljs-number >0</span>, <span class=hljs-number >10</span>)
    βpC ~ Normal(<span class=hljs-number >0</span>, <span class=hljs-number >10</span>)

    logits = α[actors] .+ (βp .+ βpC * x₁) .* x₂
    y .~ BinomialLogit.(<span class=hljs-number >1</span>, logits)
<span class=hljs-keyword >end</span>

model = m10_4(df.pulled_left, df.actor, df.condition, df.prosoc_left);</code></pre> <h2 id=output ><a href="#output">Output</a></h2> <pre><code class="julia hljs">chains = sample(model, NUTS(<span class=hljs-number >0.65</span>), <span class=hljs-number >1000</span>)</code></pre><pre><code class="plaintext hljs">Chains MCMC chain (1000×21×1 Array{Float64,3}):

Iterations        = 1:1000
Thinning interval = 1
Chains            = 1
Samples per chain = 1000
parameters        = α[1], α[2], α[3], α[4], α[5], α[6], α[7], βp, βpC
internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, max_hamiltonian_energy_error, n_steps, nom_step_size, numerical_error, step_size, tree_depth

Summary Statistics
  parameters      mean       std   naive_se      mcse        ess      rhat
      Symbol   Float64   Float64    Float64   Float64    Float64   Float64

        α[1]   -0.7694    0.2573     0.0081    0.0123   564.7170    1.0047
        α[2]   11.1799    5.4284     0.1717    0.2405   468.8232    0.9990
        α[3]   -1.0650    0.2818     0.0089    0.0152   366.7875    1.0041
        α[4]   -1.0672    0.2986     0.0094    0.0163   373.2723    0.9995
        α[5]   -0.7364    0.2694     0.0085    0.0133   471.5398    1.0023
        α[6]    0.2151    0.2675     0.0085    0.0094   509.3043    1.0016
        α[7]    1.8066    0.4075     0.0129    0.0131   549.4599    0.9990
          βp    0.8424    0.2601     0.0082    0.0130   353.5170    1.0004
         βpC   -0.1238    0.3033     0.0096    0.0128   507.1494    1.0014

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

        α[1]   -1.2916   -0.9442   -0.7702   -0.5880   -0.2699
        α[2]    3.7158    6.8740   10.2325   14.2859   24.1039
        α[3]   -1.6330   -1.2484   -1.0662   -0.8760   -0.5107
        α[4]   -1.6287   -1.2711   -1.0617   -0.8665   -0.4687
        α[5]   -1.2741   -0.9137   -0.7295   -0.5467   -0.2236
        α[6]   -0.3115    0.0403    0.2202    0.3951    0.7312
        α[7]    1.0991    1.5203    1.7771    2.0816    2.6347
          βp    0.3369    0.6777    0.8411    1.0150    1.3427
         βpC   -0.6800   -0.3424   -0.1240    0.0830    0.4973
</code></pre> </p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> StatsPlots

StatsPlots.plot(chains)</code></pre> <p> <img src="/TuringModels.jl/assets/models/estimate-handedness-chimpanzees/code/output/chains.svg" alt=""> <h2 id=original_output ><a href="#original_output">Original output</a></h2> <pre><code class="julia hljs">m_10_04s_result = <span class=hljs-string >&quot;
Iterations = 1:1000
Thinning interval = 1
Chains = 1,2,3,4
Samples per chain = 1000

Empirical Posterior Estimates:
        Mean        SD       Naive SE       MCSE      ESS
a.1 -0.74503184 0.26613979 0.0042080396 0.0060183398 1000
a.2 10.77955494 5.32538998 0.0842018089 0.1269148045 1000
a.3 -1.04982353 0.28535997 0.0045119373 0.0049074219 1000
a.4 -1.04898135 0.28129307 0.0044476339 0.0056325117 1000
a.5 -0.74390933 0.26949936 0.0042611590 0.0052178124 1000
a.6  0.21599365 0.26307574 0.0041595927 0.0045153523 1000
a.7  1.81090866 0.39318577 0.0062168129 0.0071483527 1000
bp  0.83979926 0.26284676 0.0041559722 0.0059795826 1000
bpC -0.12913322 0.29935741 0.0047332562 0.0049519863 1000
&quot;</span>;</code></pre> <div class=page-foot > <div class=copyright > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Rob Goedman, Richard Torkar, Rik Huijzer, Martin Trapp and contributors. Last modified: January 27, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div>