<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel="shortcut icon" type="image/png" href="/TuringModels.jl/assets/favicon.png"/> <link rel=stylesheet  href="/TuringModels.jl/libs/highlight/github.min.css"> <link rel=stylesheet  href="/TuringModels.jl/css/franklin.css"> <title>Estimate handedness for each Chimpanzee</title> <div class=franklin-content > <div class=top-bar > <a href="/TuringModels.jl/">TuringModels</a> </div> <h1>Estimate handedness for each Chimpanzee</h1> </div> <div class=franklin-content > <p>This is model <code>m10.4</code> in Statistical Rethinking Edition 1.</p> <div class=franklin-toc ><ol><li><a href="#data">Data</a><li><a href="#model">Model</a><li><a href="#output">Output</a><li><a href="#original_output">Original output</a></ol></div> <h2 id=data ><a href="#data">Data</a></h2> <pre><code class="julia hljs"><span class=hljs-keyword >import</span> CSV
<span class=hljs-keyword >import</span> TuringModels

<span class=hljs-keyword >using</span> DataFrames
<span class=hljs-keyword >using</span> StatsFuns

data_path = joinpath(TuringModels.project_root, <span class=hljs-string >&quot;data&quot;</span>, <span class=hljs-string >&quot;chimpanzees.csv&quot;</span>)
df = CSV.read(data_path, DataFrame; delim=<span class=hljs-string >&#x27;;&#x27;</span>)
first(df, <span class=hljs-number >10</span>)</code></pre><pre><code class="plaintext hljs">10×8 DataFrame
 Row │ actor  recipient  condition  block  trial  prosoc_left  chose_prosoc  pulled_left
     │ Int64  String     Int64      Int64  Int64  Int64        Int64         Int64
─────┼───────────────────────────────────────────────────────────────────────────────────
   1 │     1  NA                 0      1      2            0             1            0
   2 │     1  NA                 0      1      4            0             0            1
   3 │     1  NA                 0      1      6            1             0            0
   4 │     1  NA                 0      1      8            0             1            0
   5 │     1  NA                 0      1     10            1             1            1
   6 │     1  NA                 0      1     12            1             1            1
   7 │     1  NA                 0      2     14            1             0            0
   8 │     1  NA                 0      2     16            1             0            0
   9 │     1  NA                 0      2     18            0             1            0
  10 │     1  NA                 0      2     20            0             1            0</code></pre> <h2 id=model ><a href="#model">Model</a></h2> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> Turing

<span class=hljs-meta >@model</span> m10_4(y, actors, x₁, x₂) = <span class=hljs-keyword >begin</span>
    <span class=hljs-comment ># Number of unique actors in the data set</span>
    N_actor = length(unique(actors))

    <span class=hljs-comment ># Set an TArray for the priors/param</span>
    α ~ filldist(Normal(<span class=hljs-number >0</span>, <span class=hljs-number >10</span>), N_actor)
    βp ~ Normal(<span class=hljs-number >0</span>, <span class=hljs-number >10</span>)
    βpC ~ Normal(<span class=hljs-number >0</span>, <span class=hljs-number >10</span>)

    logits = α[actors] .+ (βp .+ βpC * x₁) .* x₂
    y .~ BinomialLogit.(<span class=hljs-number >1</span>, logits)
<span class=hljs-keyword >end</span>

model = m10_4(df.pulled_left, df.actor, df.condition, df.prosoc_left);</code></pre> <h2 id=output ><a href="#output">Output</a></h2> <pre><code class="julia hljs">chains = sample(model, NUTS(<span class=hljs-number >0.65</span>), <span class=hljs-number >1000</span>)</code></pre><pre><code class="plaintext hljs">Chains MCMC chain (1000×21×1 Array{Float64,3}):

Iterations        = 1:1000
Thinning interval = 1
Chains            = 1
Samples per chain = 1000
parameters        = α[1], α[2], α[3], α[4], α[5], α[6], α[7], βp, βpC
internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, max_hamiltonian_energy_error, n_steps, nom_step_size, numerical_error, step_size, tree_depth

Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64

        α[1]   -0.7369    0.2808     0.0089    0.0090    960.5307    1.0019
        α[2]   10.7674    5.3016     0.1677    0.2357    358.0624    1.0040
        α[3]   -1.0485    0.2903     0.0092    0.0077    985.5300    0.9993
        α[4]   -1.0512    0.2878     0.0091    0.0116    649.3776    1.0005
        α[5]   -0.7302    0.2689     0.0085    0.0056   1064.9215    0.9991
        α[6]    0.2153    0.2705     0.0086    0.0076    951.2244    0.9998
        α[7]    1.8131    0.3798     0.0120    0.0152    916.7462    1.0003
          βp    0.8383    0.2622     0.0083    0.0132    469.4372    0.9991
         βpC   -0.1434    0.2964     0.0094    0.0097    620.4956    1.0000

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

        α[1]   -1.2979   -0.9331   -0.7309   -0.5452   -0.1660
        α[2]    3.6937    6.6958    9.5264   13.5400   22.9320
        α[3]   -1.6194   -1.2431   -1.0547   -0.8555   -0.4693
        α[4]   -1.6924   -1.2236   -1.0391   -0.8576   -0.5231
        α[5]   -1.2596   -0.9098   -0.7329   -0.5512   -0.1938
        α[6]   -0.3244    0.0327    0.2100    0.3947    0.7624
        α[7]    1.1416    1.5488    1.8059    2.0442    2.6250
          βp    0.3697    0.6448    0.8387    1.0025    1.3823
         βpC   -0.7458   -0.3292   -0.1455    0.0537    0.4147
</code></pre> </p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> StatsPlots

StatsPlots.plot(chains)</code></pre> <p> <img src="/TuringModels.jl/assets/models/estimate-handedness-chimpanzees/code/output/chains.svg" alt=""> <h2 id=original_output ><a href="#original_output">Original output</a></h2> <pre><code class="julia hljs">m_10_04s_result = <span class=hljs-string >&quot;
Iterations = 1:1000
Thinning interval = 1
Chains = 1,2,3,4
Samples per chain = 1000

Empirical Posterior Estimates:
        Mean        SD       Naive SE       MCSE      ESS
a.1 -0.74503184 0.26613979 0.0042080396 0.0060183398 1000
a.2 10.77955494 5.32538998 0.0842018089 0.1269148045 1000
a.3 -1.04982353 0.28535997 0.0045119373 0.0049074219 1000
a.4 -1.04898135 0.28129307 0.0044476339 0.0056325117 1000
a.5 -0.74390933 0.26949936 0.0042611590 0.0052178124 1000
a.6  0.21599365 0.26307574 0.0041595927 0.0045153523 1000
a.7  1.81090866 0.39318577 0.0062168129 0.0071483527 1000
bp  0.83979926 0.26284676 0.0041559722 0.0059795826 1000
bpC -0.12913322 0.29935741 0.0047332562 0.0049519863 1000
&quot;</span>;</code></pre> <div class=page-foot > <div class=copyright > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Rob Goedman, Richard Torkar, Rik Huijzer, Martin Trapp and contributors. Last modified: January 25, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div>