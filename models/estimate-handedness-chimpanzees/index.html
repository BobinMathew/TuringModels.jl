<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel="shortcut icon" type="image/png" href="/TuringModels.jl/assets/favicon.png"/> <link rel=stylesheet  href="/TuringModels.jl/libs/highlight/github.min.css"> <link rel=stylesheet  href="/TuringModels.jl/css/franklin.css"> <title>Estimate handedness for each Chimpanzee</title> <div class=franklin-content > <div class=top-bar > <a href="/TuringModels.jl/">TuringModels</a> </div> <h1>Estimate handedness for each Chimpanzee</h1> </div> <div class=franklin-content > <p>This is model <code>m10.4</code> in Statistical Rethinking Edition 1.</p> <div class=franklin-toc ><ol><li><a href="#data">Data</a><li><a href="#model">Model</a><li><a href="#output">Output</a><li><a href="#original_output">Original output</a></ol></div> <h2 id=data ><a href="#data">Data</a></h2> <pre><code class="julia hljs"><span class=hljs-keyword >import</span> CSV
<span class=hljs-keyword >import</span> TuringModels

<span class=hljs-keyword >using</span> DataFrames
<span class=hljs-keyword >using</span> StatsFuns

data_path = joinpath(TuringModels.project_root, <span class=hljs-string >&quot;data&quot;</span>, <span class=hljs-string >&quot;chimpanzees.csv&quot;</span>)
df = CSV.read(data_path, DataFrame; delim=<span class=hljs-string >&#x27;;&#x27;</span>)
first(df, <span class=hljs-number >10</span>)</code></pre><pre><code class="plaintext hljs">10×8 DataFrame
 Row │ actor  recipient  condition  block  trial  prosoc_left  chose_prosoc  pulled_left
     │ Int64  String     Int64      Int64  Int64  Int64        Int64         Int64
─────┼───────────────────────────────────────────────────────────────────────────────────
   1 │     1  NA                 0      1      2            0             1            0
   2 │     1  NA                 0      1      4            0             0            1
   3 │     1  NA                 0      1      6            1             0            0
   4 │     1  NA                 0      1      8            0             1            0
   5 │     1  NA                 0      1     10            1             1            1
   6 │     1  NA                 0      1     12            1             1            1
   7 │     1  NA                 0      2     14            1             0            0
   8 │     1  NA                 0      2     16            1             0            0
   9 │     1  NA                 0      2     18            0             1            0
  10 │     1  NA                 0      2     20            0             1            0</code></pre> <h2 id=model ><a href="#model">Model</a></h2> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> Turing

<span class=hljs-meta >@model</span> m10_4(y, actors, x₁, x₂) = <span class=hljs-keyword >begin</span>
    <span class=hljs-comment ># Number of unique actors in the data set</span>
    N_actor = length(unique(actors))

    <span class=hljs-comment ># Set an TArray for the priors/param</span>
    α ~ filldist(Normal(<span class=hljs-number >0</span>, <span class=hljs-number >10</span>), N_actor)
    βp ~ Normal(<span class=hljs-number >0</span>, <span class=hljs-number >10</span>)
    βpC ~ Normal(<span class=hljs-number >0</span>, <span class=hljs-number >10</span>)

    logits = α[actors] .+ (βp .+ βpC * x₁) .* x₂
    y .~ BinomialLogit.(<span class=hljs-number >1</span>, logits)
<span class=hljs-keyword >end</span>

model = m10_4(df.pulled_left, df.actor, df.condition, df.prosoc_left);</code></pre> <h2 id=output ><a href="#output">Output</a></h2> <pre><code class="julia hljs">chains = sample(model, NUTS(<span class=hljs-number >0.65</span>), <span class=hljs-number >1000</span>)</code></pre><pre><code class="plaintext hljs">Chains MCMC chain (1000×21×1 Array{Float64,3}):

Iterations        = 1:1000
Thinning interval = 1
Chains            = 1
Samples per chain = 1000
parameters        = α[1], α[2], α[3], α[4], α[5], α[6], α[7], βp, βpC
internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, max_hamiltonian_energy_error, n_steps, nom_step_size, numerical_error, step_size, tree_depth

Summary Statistics
  parameters      mean       std   naive_se      mcse        ess      rhat
      Symbol   Float64   Float64    Float64   Float64    Float64   Float64

        α[1]   -0.7348    0.2660     0.0084    0.0064   896.3447    0.9990
        α[2]   11.1781    5.4978     0.1739    0.3561   231.0321    1.0231
        α[3]   -1.0611    0.2774     0.0088    0.0101   755.3169    0.9990
        α[4]   -1.0548    0.2775     0.0088    0.0088   738.8620    0.9996
        α[5]   -0.7484    0.2555     0.0081    0.0121   583.6704    0.9992
        α[6]    0.2126    0.2820     0.0089    0.0141   638.8116    1.0002
        α[7]    1.8126    0.4068     0.0129    0.0130   987.3090    0.9992
          βp    0.8484    0.2651     0.0084    0.0172   502.2966    1.0011
         βpC   -0.1431    0.2937     0.0093    0.0132   617.3239    1.0014

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol   Float64   Float64   Float64   Float64   Float64

        α[1]   -1.2406   -0.9094   -0.7344   -0.5577   -0.2075
        α[2]    4.0952    6.8071   10.0335   14.5691   24.1757
        α[3]   -1.6240   -1.2520   -1.0497   -0.8837   -0.5103
        α[4]   -1.6063   -1.2535   -1.0477   -0.8645   -0.5010
        α[5]   -1.2456   -0.9203   -0.7504   -0.5817   -0.2360
        α[6]   -0.3799    0.0292    0.2064    0.3887    0.7826
        α[7]    1.0763    1.5356    1.7850    2.0759    2.6141
          βp    0.3173    0.6732    0.8465    1.0357    1.3557
         βpC   -0.7177   -0.3493   -0.1380    0.0687    0.4254
</code></pre> </p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> StatsPlots

StatsPlots.plot(chains)</code></pre> <p> <img src="/TuringModels.jl/assets/models/estimate-handedness-chimpanzees/code/output/chains.svg" alt=""> <h2 id=original_output ><a href="#original_output">Original output</a></h2> <pre><code class="julia hljs">m_10_04s_result = <span class=hljs-string >&quot;
Iterations = 1:1000
Thinning interval = 1
Chains = 1,2,3,4
Samples per chain = 1000

Empirical Posterior Estimates:
        Mean        SD       Naive SE       MCSE      ESS
a.1 -0.74503184 0.26613979 0.0042080396 0.0060183398 1000
a.2 10.77955494 5.32538998 0.0842018089 0.1269148045 1000
a.3 -1.04982353 0.28535997 0.0045119373 0.0049074219 1000
a.4 -1.04898135 0.28129307 0.0044476339 0.0056325117 1000
a.5 -0.74390933 0.26949936 0.0042611590 0.0052178124 1000
a.6  0.21599365 0.26307574 0.0041595927 0.0045153523 1000
a.7  1.81090866 0.39318577 0.0062168129 0.0071483527 1000
bp  0.83979926 0.26284676 0.0041559722 0.0059795826 1000
bpC -0.12913322 0.29935741 0.0047332562 0.0049519863 1000
&quot;</span>;</code></pre> <div class=page-foot > <div class=copyright > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Rob Goedman, Richard Torkar, Rik Huijzer, Martin Trapp and contributors. Last modified: January 25, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div>