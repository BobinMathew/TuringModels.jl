<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel="shortcut icon" type="image/png" href="/TuringModels.jl/assets/favicon.png"/> <link rel=stylesheet  href="/TuringModels.jl/libs/highlight/github.min.css"> <link rel=stylesheet  href="/TuringModels.jl/css/franklin.css"> <title>Wild chain</title> <div class=franklin-content > <div class=top-bar > <a href="/TuringModels.jl/">TuringModels</a> </div> <h1>Wild chain</h1> </div> <div class=franklin-content > <p>This model shows what happens if you use extremely flat priors, and is fixed in <a href="/TuringModels.jl/models/weakly-informative-priors">Weakly Informative Priors</a>.</p> <div class=franklin-toc ><ol><li><a href="#data">Data</a><li><a href="#model">Model</a><li><a href="#output">Output</a></ol></div> <h2 id=data ><a href="#data">Data</a></h2> <pre><code class="julia hljs">y = [-<span class=hljs-number >1</span>, <span class=hljs-number >1</span>]</code></pre><pre><code class="plaintext hljs">2-element Array{Int64,1}:
 -1
  1</code></pre> <h2 id=model ><a href="#model">Model</a></h2> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> Turing

<span class=hljs-meta >@model</span> <span class=hljs-keyword >function</span> m8_2(y)
    σ ~ FlatPos(<span class=hljs-number >0.0</span>) <span class=hljs-comment >## improper prior with probability one everywhere above 0.0</span>
    α ~ Flat() <span class=hljs-comment >## improper prior with pobability one everywhere</span>

    y .~ Normal(α, σ)
<span class=hljs-keyword >end</span>;</code></pre> <h2 id=output ><a href="#output">Output</a></h2> <pre><code class="julia hljs">chains = sample(m8_2(y), NUTS(<span class=hljs-number >0.65</span>), <span class=hljs-number >1000</span>)</code></pre><pre><code class="plaintext hljs">Chains MCMC chain (1000×14×1 Array{Float64,3}):

Iterations        = 1:1000
Thinning interval = 1
Chains            = 1
Samples per chain = 1000
parameters        = α, σ
internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, max_hamiltonian_energy_error, n_steps, nom_step_size, numerical_error, step_size, tree_depth

Summary Statistics
  parameters         mean          std    naive_se        mcse       ess      rhat
      Symbol      Float64      Float64     Float64     Float64   Float64   Float64

           α   -1807.0160    8879.0555    280.7804   2454.0020    7.6031    1.1149
           σ   12701.3610   61569.8906   1947.0109   8088.8278   69.2218    1.0016

Quantiles
  parameters          2.5%      25.0%     50.0%       75.0%        97.5%
      Symbol       Float64    Float64   Float64     Float64      Float64

           α   -34001.3616   -16.2802   -1.4371     43.2939    4976.8191
           σ        5.2647    11.2093   68.4477   2224.5232   96851.6039
</code></pre> </p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> StatsPlots

StatsPlots.plot(chains)</code></pre> <p> <img src="/TuringModels.jl/assets/models/wild-chain/code/output/chains.svg" alt=""> <div class=page-foot > <div class=copyright > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Rob Goedman, Richard Torkar, Rik Huijzer, Martin Trapp and contributors. Last modified: January 27, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div>